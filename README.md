# Image-Aware Reasoning Assistant

A mini multimodal system that analyzes an image for e-commerce suitability using object detection, OCR, and LLM reasoning.

## Project Structure

image_reasoning_assistant/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ config.py                           # Configuration settings
â”œâ”€â”€ feature_extractor.py                # Pre-LLM feature extraction
â”œâ”€â”€ llm_reasoner.py                     # LLM + rule-based reasoning
â”œâ”€â”€ main.py                             # Main pipeline orchestrator
â”œâ”€â”€ create_test_images.py               # Generate test images
â”œâ”€â”€ test_multiple_images.py             # Batch testing script
â”œâ”€â”€ .env.example                        # Environment template
â”œâ”€â”€ samples/                            # Test images directory
â”‚   â”œâ”€â”€ professional_product.jpg       # Clean product image
â”‚   â”œâ”€â”€ sample1.jpg                    # Casual photo (person + bed)
â”‚   â””â”€â”€ blurry_test.jpg                # Blurry test image
â””â”€â”€ analysis_output_*.json             # Generated analysis files

## ðŸš€ Quick Start

# 1. Installation

# Clone repository
git clone <your-repo-url>
cd image_reasoning_assistant

# Install dependencies
pip install -r requirements.txt

# Install Tesseract OCR (Windows)
Download from: https://github.com/UB-Mannheim/tesseract/wiki
Default path: C:\Program Files\Tesseract-OCR\tesseract.exe

# 2. Configuration
# Edit .env with your API keys
OPENAI_API_KEY=your_openai_key_here
GEMINI_API_KEY=your_gemini_key_here

# 3. Generate Test Images
python create_test_images.py
# Creates 3 sample images in 'samples/' folder

# 4. Run Analysis
# Analyze single image
python main.py samples/professional_product.jpg

# Run batch tests
python test_multiple_images.py

## ðŸ”§ System Architecture
Image Input
    â†“
[1] Feature Extraction (Pre-LLM Intelligence)
    â”œâ”€â”€ Object Detection (YOLO11n)
    â”œâ”€â”€ Text Extraction (Tesseract OCR)
    â””â”€â”€ Blur Analysis (Laplacian Variance)
    â†“
[2] Hybrid Reasoning Layer
    â”œâ”€â”€ LLM Analysis (Gemini/OpenAI)
    â”œâ”€â”€ Rule-Based Validation
    â””â”€â”€ Intelligent Result Blending
    â†“
[3] Structured Output (JSON) 

# Key Components
FeatureExtractor - Extracts 3+ visual features before LLM

LLMReasoner - Hybrid analysis with fallback mechanisms

MultimodalAnalyzer - Orchestrates the complete pipeline

## ðŸŽ¯ Core Features
# âœ… Pre-LLM Feature Extraction
Object Detection: YOLO11n detects 80+ object classes

Text Extraction: Tesseract OCR with preprocessing

Quality Assessment: Blur detection via Laplacian variance

# âœ… Intelligent Reasoning
LLM Integration: Gemini/OpenAI with structured prompting

Rule-Based Fallback: Comprehensive scoring system

Validation Logic: Cross-checks LLM outputs

# âœ… Structured Output
{
  "image_quality_score": 0.85,
  "issues_detected": ["background clutter", "poor lighting"],
  "detected_objects": ["shoe", "hand"],
  "text_detected": [],
  "llm_reasoning_summary": "The image shows...",
  "final_verdict": "Suitable for professional e-commerce use",
  "confidence": 0.82
}

